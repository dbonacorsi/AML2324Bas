{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.13"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"1aH0eozRAWhR"},"source":["# Prepare your data for ML"]},{"cell_type":"markdown","metadata":{"id":"auiUyG_Lauxp"},"source":["Key items for an introductory discussion on this topic:\n","* ML systems: \"you just send data into a black box\", this is not correct!\n","* are ML systems agnostic about the data they receive?"]},{"cell_type":"markdown","metadata":{"id":"ILCmKFdWAWhS"},"source":["Let's explore how to prepare your data in Python in such a way to best expose the structure of the problem to the ML algorithms, and we will do it by using ***scikit-learn***. Focus will be on:\n","\n","1. Rescaling the data\n","2. Standardizing the data\n","3. Normalizing the data\n","4. Binarizing the data"]},{"cell_type":"markdown","metadata":{"id":"S8KFOXs8pnSC"},"source":["\n","\n","NOTE: this is not carved in stones. Different approaches exist in applied ML. Most important take-away message from this part is: be very careful about how you prepare your data _before_ trying out any ML algorithm..\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PwZIMYs-AWhj"},"source":["## How to do this? Scikit-learn"]},{"cell_type":"markdown","metadata":{"id":"v0LQRYgfAWhk"},"source":["The ***scikit-learn*** library provides two standard idioms for transforming data. Each is useful in different circumstances.\n","\n","* Fit and Multiple Transform\n","* Combined Fit-And-Transform\n","\n","You can review the [preprocess API in scikit-learn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing), where all the calls are listed and explained in details."]},{"cell_type":"markdown","metadata":{"id":"cWMSg-15AWhp"},"source":["All pre-installed in Colab.. but if you are working locally and you do not have it, just do:\n","\n","    pip install -U scikit-learn\n","\n","(`-U` means \"Upgrade all specified packages to the newest available version\")or (on anaconda):\n","\n","    conda install scikit-learn"]},{"cell_type":"markdown","metadata":{"id":"QxIBnPH-pzIe"},"source":["For us now: we are running on Colab, so we need to do nothing - all pre-installed for us, just need some imports."]},{"cell_type":"markdown","metadata":{"id":"6NyHWASMpbyq"},"source":["## 0. Import the data"]},{"cell_type":"code","metadata":{"id":"egGmPYr6pblR"},"source":["import pandas as pd\n","\n","url = 'https://raw.githubusercontent.com/dbonacorsi/AMLBas2324/main/pima-indians-diabetes.data.csv'\n","\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","data = pd.read_csv(url, names=names)\n","data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2a0nJAUbAWhx"},"source":["## 1. Rescale data"]},{"cell_type":"markdown","metadata":{"id":"20rOxkL6AWhy"},"source":["You can rescale your data using scikit-learn using the MinMaxScaler class, documented [here](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)."]},{"cell_type":"code","metadata":{"id":"qPxwsEgYAWh0"},"source":["from numpy import set_printoptions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tue3_mY4AWh5"},"source":["from sklearn.preprocessing import MinMaxScaler   # <--- note from where, in sklearn, we import what we need..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sWBMr249AWh-"},"source":["array = data.values\n","array"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5l4fo6fkqSTf"},"source":["type(array)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PhbX-pLQAWiE"},"source":["# separate array into input and output components\n","X = array[:,0:8]\n","Y = array[:,8]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OrygGW7fAWiJ"},"source":["X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ASehFIydAWiN"},"source":["Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"_OQlfm3sAWiR"},"source":["# Rescale data (between 0 and 1)\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","rescaledX = scaler.fit_transform(X)    # <--- this is an example of a fit-and-transform paradigm in sklearn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4dBzMdM2dTzw"},"source":["# summarize original data...\n","set_printoptions(precision=3)\n","print(X[0:5,:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jg0ckAc7AWiV"},"source":["#.. and rescaled data\n","print(rescaledX[0:79,:])   # first few rows, you see 8 feature columns rescaled"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nu1_zTWwAWiZ"},"source":["### <font color='red'>Exercise 1</font>"]},{"cell_type":"markdown","metadata":{"id":"7WRc2McqAWia"},"source":["Try changing the feature range in the scaling: e.g. put (0,10). Make sure you understand what it does. Try different ranges to get familiar.\n"]},{"cell_type":"code","metadata":{"id":"2zjrcu6NrSQ-"},"source":["### put your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"scYktrZnAWib"},"source":["### <font color='red'>Exercise 2</font>"]},{"cell_type":"markdown","metadata":{"id":"PGX97dhUAWib"},"source":["Can you change this from a combined fit-and-transform to a fit first then transform (just once) later?\n","\n","_(HINT: to do this, you need to browse in the sklearn documentation and find the proper syntax)_"]},{"cell_type":"code","metadata":{"id":"-_8gOmpwAWid"},"source":["### put your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GA1OGIgqAWij"},"source":["## 2. Standardize data"]},{"cell_type":"markdown","metadata":{"id":"XAzQfAlkAWij"},"source":["You can standardize data using scikit-learn with the StandardScaler, documented [here](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."]},{"cell_type":"code","metadata":{"id":"V8GUjZFsAWik"},"source":["from sklearn.preprocessing import StandardScaler   # <--- note from where, in sklearn, we import what we need..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qWXbwtWXAWit"},"source":["# Standardize data (0 mean, 1 stdev)\n","scaler = StandardScaler().fit(X)      # <--- this is FIT (an example of a fit first, and transform later (the other paradigm in sklearn)\n","rescaledX = scaler.transform(X)       # <--- this is TRANSFORM (an example of a fit first, and transform later (the other paradigm in sklearn)\n","\n","# summarize transformed data\n","set_printoptions(precision=3)\n","print(rescaledX[0:10,:])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yu0EFJbeAWiw"},"source":["The values for each attribute now have a mean value of 0 and a standard deviation of 1."]},{"cell_type":"markdown","metadata":{"id":"TTBSAEtTAWix"},"source":["## 3. Normalize data"]},{"cell_type":"markdown","metadata":{"id":"kh1BLHn7AWiy"},"source":["You can normalize data in Python with scikit-learn using the Normalizer class, documented [here](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html)."]},{"cell_type":"code","metadata":{"id":"yLFwEc-UAWiz"},"source":["from sklearn.preprocessing import Normalizer   # <--- note from where, in sklearn, we import what we need..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"BhcFt1iJAWi3"},"source":["# Normalize data (length of 1)\n","scaler = Normalizer().fit(X)\n","normalizedX = scaler.transform(X)\n","\n","# summarize transformed data\n","set_printoptions(precision=3)\n","print(normalizedX[0:10,:])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KZBGKCcbAWi6"},"source":["An alternative way, still in scikit-learn:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Od8VMHwXAWi9"},"source":["#from sklearn import preprocessing\n","from sklearn.preprocessing import normalize\n","\n","alternative_normalizedX = normalize(X)\n","alternative_normalizedX"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"otM0hFqVAWjE"},"source":["### <font color='red'>Exercise 3</font>"]},{"cell_type":"markdown","metadata":{"id":"01BTkbOsAWjF"},"source":["The rows should now be normalized to length 1. Check it out this is true for both methods above."]},{"cell_type":"markdown","metadata":{"id":"lSp8rc-ciih3"},"source":["Note that you can compare both l2-norm (default) and l1-norm:\n","\n","**l1-norm**: also called least absolute deviations (LAD), or least absolute errors (LAE). It is minimizing the sum of the absolute differences between target (y) and estimated (x) values:\n","\n","   $$\\sum_{i=1}^n |y_i - f(x_i)|$$\n","\n","**l2-norm**: also known as least squares. It is  minimizing the sum of the squares of the differences between target (y) and estimated (x) values:\n","\n","   $$\\sum_{i=1}^n (y_i - f(x_i))^2$$\n","\n","_(HINT: you need to check the scikit-learn documentation for `preprocessing.normalize` to find how to choose among these options, then the rest is implementation in python..)_\n"]},{"cell_type":"code","metadata":{"id":"NT088OoPAWjG"},"source":["### put your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m6UyUXTXAWjV"},"source":["## 4. Binarize data"]},{"cell_type":"markdown","metadata":{"id":"yY6q2DiQAWjV"},"source":["You can normalize data in Python with scikit-learn using the Binarizer class, documented [here](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Binarizer.html)."]},{"cell_type":"code","metadata":{"id":"Z0YZXywVAWjX"},"source":["from sklearn.preprocessing import Binarizer   # <--- note from where, in sklearn, we import what we need..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"slNWkB9-AWjr"},"source":["# binarization\n","binarizer = Binarizer(threshold=0.0).fit(X)\n","binaryX = binarizer.transform(X)\n","# summarize transformed data\n","set_printoptions(precision=3)\n","print(binaryX[0:20,:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rv1QkOUUAWjw"},"source":["# .. compare with original data\n","print(X[0:5,:])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZUgBkw80AWkX"},"source":["## Summary"]},{"cell_type":"markdown","metadata":{"id":"NmG9cLTMAWkX"},"source":["What we did:\n","\n","* we discovered how you can prepare your data for ML in Python using scikit-learn, with 4 recipes."]},{"cell_type":"markdown","metadata":{"id":"n0v_pezpAWkY"},"source":["## What's next"]},{"cell_type":"markdown","metadata":{"id":"sHukPZWjAWkY"},"source":["Now that we know how to transform the data to best expose the structure of my problem to the modeling algorithms, we need now to discover how to select the features of my data that are most relevant to making predictions."]}]}